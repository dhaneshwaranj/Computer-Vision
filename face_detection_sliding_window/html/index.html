<html>
<head>
<title>Project 5</title>
<link href='http://fonts.googleapis.com/css?family=Nunito:300|Crimson+Text|Droid+Sans+Mono'
 rel='stylesheet' type='text/css'>
<link rel="stylesheet" title="Default" href="styles/github.css">
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>  

<link rel="stylesheet" href="highlighting/styles/default.css">
<script src="highlighting/highlight.pack.js"></script>

<style type="text/css">
body {
	margin: 0px;
	width: 100%;
	font-family: 'Crimson Text', serif;
	font-size: 20px;
	background: #fcfcfc;
}
h1 {
	font-family: 'Nunito', sans-serif;
	font-weight: high;
	font-size: 42px;
	margin: 25px 0px 0px 0px;
	word-spacing: 4px;
}

h2 {
	font-family: 'Nunito', sans-serif;
	font-weight: high;
	font-size: 32px;
	margin: 15px 0px 0px 0px;
	color: #333;	
	word-spacing: 3px;
}

h3 {
	font-family: 'Nunito', sans-serif;
	font-weight: high
	font-size: 26px;
	margin: 15px 0px 0px 0px;
	color: #000;
	word-spacing: 2px;
}
h4 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 22px;
	margin: 10px 0px 10px 0px;
	color: #333;
	word-spacing: 2px;
}

h5 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 18px;
	margin: 10px 0px 10px 0px;
	color: #111;
	word-spacing: 2px;
}

h6 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 30px;
	margin: 0px 0px 0px 0px;
	word-spacing: 4px;
}

h7 {
	font-family: 'Nunito', sans-serif;
	font-weight: high;
	font-size: 22px;
	margin: 15px 0px 0px 0px;
	color: #333;	
	word-spacing: 3px;
}

h8 {
	font-family: 'Nunito', sans-serif;
	font-weight: high;
	font-size: 18px;
	margin: 15px 0px 0px 0px;
	color: #333;	
	word-spacing: 3px;
}

h9 {
	font-family: 'Nunito', sans-serif;
	font-weight: high;
	font-size: 22px;
	margin: 15px 0px 0px 0px;
	color: #333;	
	word-spacing: 3px;
}

p, li {
	color: #444;
}

a {
	color: #DE3737;
}

.container {
	margin: 0px auto 0px auto;
	width: 960px;
}

#header {
	background: #333;
	width: 100%;
}

#headersub {
	color: #ccc;
	width: 960px;
	margin: 0px auto 0px auto;
	padding: 20px 0px 20px 0px;
}

.chart {
	width: 480px;
}
.lol {
	font-size: 16px;
	color: #888;
	font-style: italic;
}
.sep {
	height: 1px;
	width: 100%;
	background: #999;
	margin: 20px 0px 20px 0px;
}
.footer{
	font-size: 16px;
}
.latex {
	width: 100%;
}

.latex img {
	display: block;
	margin: 0px auto 0px auto;
}

pre {
	font-family: 'Droid Sans Mono';
	font-size: 14px;
}

td img {
  vertical-align: middle;
}

#contents a {
}
</style>
<script type="text/javascript">
    hljs.initHighlightingOnLoad();
</script>
</head>
<body>
<div id="header" >
<div id="headersub">
<h1><span style="color: #DE3737">Dhaneshwaran Jotheeswaran</span></h1>
<h6><span style="color: #DE3737">903204867</span></h6>
</div>
</div>
<div class="container">

<h2><center><b>Project 5: Face Detection with a Sliding Window</b></center></h2>


<p style="text-align:justify"> The goal of this project is to get introduced to Object 
Detection. The sliding window model is conceptually simple: independently classify all 
image patches as being object or non-object. Sliding window classification is the dominant 
paradigm in object detection and for one object category in particular - faces - it is one 
of the most noticeable successes of computer vision. For example, modern cameras and photo 
organization tools have prominent face detection capabilities. </p>

<table>
<tr>
<td><img src="im1.png" width="100%"/></td>
</tr>
<tr>
<td><img src="pipeline.png" width="100%"/></td>
</tr>
<tr>
<td><center>Project Pipeline</td>
</tr>
</table>

<p style="text-align:justify"> So, we had to do the following steps:</p>
<ol>
<li>Get Positive Image Features</li>
<li>Get Negative Image Features</li>
<li>Train model for Face Detection</li>
<li>Get Test Image Features</li>
<li>Detect Faces using the Learned Model</li>
</ol>

<div style="clear:both">
<h6><b>Getting Image Features</b></h6>
<h3><b>Positive Image Features</b></h3>
<p style="text-align:justify"> We were given bunch of images with just faces for getting 
Positive Examples. I called the vl_feat's HoG feature extractor, and got the HoG features 
for the Face images. Also, I flipped the image to get synthetic Positive examples, and also, 
rotated the images to a small degree and got more Positive Examples. </p>

<h3><b>Negative Image Features</b></h3>
<p style="text-align:justify"> We were given many images with no faces for getting Negative 
Examples. But, these images didn't have a fixed dimensions. But, we had to get 36x36 sized 
images, because the positive images were that size and we got the positive HoG features for 
this size. So, I shuffled the images, then got 36x36 crops from the image. The number of 
such crops was proportional to the number of pixels in the image. I called the vl_feat's HoG feature extractor, and got the HoG features 
for the Negative Example images.</p>

<div style="clear:both">
<h6><b>Classifier</b></h6>
<h3><b>Linear Support Vector Machine</b></h3>
<p style="text-align:justify">Linear classifiers are one of the simplest possible learning 
models. The feature space is partitioned by a learned hyperplane and test cases 
are categorized based on which side of that hyperplane they fall on. There are numerous 
methods to learn linear classifiers but we will find linear decision boundaries with a 
support vector machine. We didn't have to code up the learning algorithm. We used the 
vl_feat's SVM trainer function and got the Weight Vector and Bias. </p>

<div style="clear:both">
<h6><b>Detection</b></h6>
<p style="text-align:justify">With the learned weights and bias, we now have everything 
needed to classify the test images. We take the test image, and get the HoG features for the 
image. We take 36x36 patches of the image and put it through the linear classifier, and get 
the confidences for each window. Do this for muliple scales and get the confidences for each 
patch and get the corresponding bounding boxes in the image. Now, do non-maximum suppression 
to eliminate repetitive Bounding Boxes in the image. </p>

<h6><b>Parameter Tuning</b></h6>
<p style="text-align:justify"> I tweaked the following parameters. </p>

<h3><b>HoG Feature Cellsize</b></h3>
<p style="text-align:justify"> I ran the project for cellsizes 6, 4, and 3. And as expected 
smaller cellsizes had better accuracies, but, took longer time to run. Not too long though. 
</p>

<h3><b></b>Number of Negative Examples</h3>
<p style="text-align:justify"> I played around with the number of negative examples I used 
for training. Higher worked better most of the times. </p>

<h3><b>Degress rotated in the Positive Examples</b></h3>
<p style="text-align:justify"> I rotated it till 9degress with steps of 3degrees, on both 
directions. </p>

<h3><b></b>Lambda in SVM</h3>
<p style="text-align:justify"> I tweaked the Lambda value (the regularization value) in the 
SVM function to 0.0001, and this gave me the best results among all the lambda values I 
chose, which were 0.01, 0.001, 0.0001 and 0.00001. </p>

<h3><b>Scaling Images</b></h3>
<p style="text-align:justify"> I did multiple scaling factors, starting from 100% and 
reducing it by 5% at each scale and ending at 5%. I understand that it was an overkill, but 
it wasn't too computationally expensive. And I stopped if the image became smaller than 36 
along any of the dimensions. </p>


<div style="clear:both">
<h6><b>Results</b></h6>
<div class="container">

<h3>HoG Templates</h3>
<center> Cellsize 6
<img src="hog_template6.png">
</center>
<center> Cellsize 4
<img src="hog_template4.png">
</center>
<center> Cellsize 3
<img src="hog_template3.png">
</center>

<h3>Precision Recall</h3>
<img src="average_precision.png">

<h3>Detections</h3>
<img src="res1.png">
<img src="res2.png">
<img src="res3.png">
<img src="res4.png">
<img src="res5.png">
<img src="res6.png">
<img src="res7.png">
<img src="res8.png">
<img src="res9.png">
<img src="res10.png">
<img src="res11.png">
<img src="res12.png">
<img src="res13.png">
<img src="res14.png">

</center>
</table>

</body>
</html>
